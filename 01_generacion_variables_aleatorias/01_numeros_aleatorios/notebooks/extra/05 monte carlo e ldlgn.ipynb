{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "874ad125",
   "metadata": {},
   "source": [
    "La relación es directa y, de hecho, la **Ley de los Grandes Números (LGN)** es la **base teórica** que justifica por qué los métodos de **Monte Carlo** funcionan.\n",
    "\n",
    "---\n",
    "\n",
    "## 1️⃣ Repaso de la Ley de los Grandes Números\n",
    "\n",
    "La LGN (en su versión fuerte o débil) dice que si $X_1, X_2, \\dots, X_n$ son variables aleatorias independientes e idénticamente distribuidas con esperanza $E[X] = \\mu$, entonces:\n",
    "\n",
    "$$\n",
    "\\overline{X}_n = \\frac{1}{n} \\sum_{i=1}^n X_i \\xrightarrow{n \\to \\infty} \\mu \\quad \\text{(casi seguramente o en probabilidad)}.\n",
    "$$\n",
    "\n",
    "Es decir, la **media muestral converge al valor esperado verdadero** cuando el tamaño de muestra $n$ crece.\n",
    "\n",
    "---\n",
    "\n",
    "## 2️⃣ Fundamento de Monte Carlo\n",
    "\n",
    "En Monte Carlo queremos estimar un valor esperado que muchas veces es una integral:\n",
    "\n",
    "$$\n",
    "\\theta = E[g(X)] = \\int g(x) f_X(x) \\, dx\n",
    "$$\n",
    "\n",
    "Si generamos $n$ muestras $X_1, \\dots, X_n \\sim f_X(x)$, podemos aproximar:\n",
    "\n",
    "$$\n",
    "\\theta \\approx \\frac{1}{n} \\sum_{i=1}^n g(X_i)\n",
    "$$\n",
    "\n",
    "Y **la LGN garantiza que esta aproximación converge a $\\theta$** cuando $n \\to \\infty$.\n",
    "\n",
    "---\n",
    "\n",
    "## 3️⃣ Ejemplo en el contexto clásico\n",
    "\n",
    "Supongamos que queremos calcular:\n",
    "\n",
    "$$\n",
    "\\theta = \\int_{0}^1 e^{-x^2} \\, dx\n",
    "$$\n",
    "\n",
    "No es elemental, pero podemos interpretarlo como $E[g(U)]$ donde $U \\sim \\text{Uniform}(0,1)$ y $g(u) = e^{-u^2}$.\n",
    "Generamos $U_1, \\dots, U_n$ y calculamos:\n",
    "\n",
    "$$\n",
    "\\hat{\\theta}_n = \\frac{1}{n} \\sum_{i=1}^n e^{-U_i^2}\n",
    "$$\n",
    "\n",
    "La LGN asegura que $\\hat{\\theta}_n \\to \\theta$, y Monte Carlo es simplemente aplicar esta convergencia para estimar integrales, probabilidades, precios de opciones, etc.\n",
    "\n",
    "---\n",
    "\n",
    "## 4️⃣ Interpretación conceptual\n",
    "\n",
    "* **LGN** = teoría → dice que promediar muchas simulaciones se acerca a la verdad.\n",
    "* **Monte Carlo** = práctica → usa aleatoriedad para calcular promedios que representan integrales o esperanzas, confiando en que la LGN hará que el error se reduzca con $n$.\n",
    "\n",
    "---\n",
    "\n",
    "Si quieres, puedo prepararte un **gráfico interactivo** en Plotly donde se vea cómo un estimador Monte Carlo converge a una integral real gracias a la LGN, para que la conexión sea visual y numérica al mismo tiempo.\n",
    "¿Quieres que lo haga?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2eccfb",
   "metadata": {},
   "source": [
    "# **A Manita**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9c30ab",
   "metadata": {},
   "source": [
    "Perfecto, vamos a desarrollarlo **a mano** y con toda la teoría como si fuera parte de un examen, hilando los conceptos de **valor esperado**, **ley de los grandes números** y **método de Monte Carlo** paso a paso.\n",
    "\n",
    "---\n",
    "\n",
    "## 1️⃣ Planteamiento del problema\n",
    "\n",
    "Queremos calcular la integral:\n",
    "\n",
    "$$\n",
    "\\theta = \\int_{0}^1 e^{-x^2} \\, dx\n",
    "$$\n",
    "\n",
    "* Esta integral **no es elemental**: no existe una antiderivada cerrada en términos de funciones elementales.\n",
    "* Sin embargo, sabemos que está relacionada con la función error:\n",
    "\n",
    "  $$\n",
    "  \\theta = \\frac{\\sqrt{\\pi}}{2} \\, \\mathrm{erf}(1)\n",
    "  $$\n",
    "\n",
    "  pero supongamos que **no conocemos esa fórmula** y queremos aproximarla numéricamente.\n",
    "\n",
    "---\n",
    "\n",
    "## 2️⃣ Relación con el valor esperado\n",
    "\n",
    "Sea $U \\sim \\text{Uniform}(0,1)$.\n",
    "\n",
    "El valor esperado de una función $g(U)$ está definido como:\n",
    "\n",
    "$$\n",
    "E[g(U)] = \\int_{0}^1 g(u) \\cdot f_U(u) \\, du\n",
    "$$\n",
    "\n",
    "donde $f_U(u)$ es la función de densidad de $U$.\n",
    "\n",
    "Para $U \\sim \\text{Uniform}(0,1)$, la densidad es:\n",
    "\n",
    "$$\n",
    "f_U(u) = 1, \\quad 0 \\le u \\le 1\n",
    "$$\n",
    "\n",
    "Por lo tanto:\n",
    "\n",
    "$$\n",
    "E[g(U)] = \\int_{0}^1 g(u) \\cdot 1 \\, du = \\int_{0}^1 g(u) \\, du\n",
    "$$\n",
    "\n",
    "Si elegimos $g(u) = e^{-u^2}$, la integral que queremos se convierte exactamente en:\n",
    "\n",
    "$$\n",
    "\\theta = \\int_{0}^1 e^{-x^2} \\, dx = E[g(U)]\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## 3️⃣ Interpretación probabilística\n",
    "\n",
    "Esto significa que **la integral es el valor esperado de $e^{-U^2}$** cuando $U$ se distribuye uniformemente en $[0,1]$.\n",
    "\n",
    "En términos intuitivos:\n",
    "\n",
    "* Imaginamos que generamos muchos valores aleatorios uniformes $U_i$ entre 0 y 1.\n",
    "* Para cada uno calculamos $e^{-U_i^2}$.\n",
    "* Si hacemos el promedio, nos acercaremos al valor verdadero de la integral.\n",
    "\n",
    "---\n",
    "\n",
    "## 4️⃣ Ley de los Grandes Números (LGN)\n",
    "\n",
    "La **LGN** establece que si $X_1, X_2, \\dots$ son variables aleatorias i.i.d. con valor esperado $\\mu$, entonces:\n",
    "\n",
    "$$\n",
    "\\bar{X}_n = \\frac{1}{n} \\sum_{i=1}^n X_i \\xrightarrow{n \\to \\infty} \\mu\n",
    "$$\n",
    "\n",
    "en probabilidad (y casi seguro en la forma fuerte).\n",
    "\n",
    "En nuestro caso:\n",
    "\n",
    "* $X_i = e^{-U_i^2}$ con $U_i \\stackrel{i.i.d.}{\\sim} \\text{Uniform}(0,1)$\n",
    "* $\\mu = \\theta$ (lo que queremos)\n",
    "* La LGN garantiza que:\n",
    "\n",
    "$$\n",
    "\\hat{\\theta}_n = \\frac{1}{n} \\sum_{i=1}^n e^{-U_i^2} \\to \\theta\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## 5️⃣ Método de Monte Carlo\n",
    "\n",
    "El **método de Monte Carlo** es exactamente **usar la LGN como técnica numérica**:\n",
    "\n",
    "1. Generar $U_1, \\dots, U_n \\stackrel{i.i.d.}{\\sim} \\text{Uniform}(0,1)$\n",
    "2. Calcular $g(U_i) = e^{-U_i^2}$\n",
    "3. Tomar el promedio:\n",
    "\n",
    "   $$\n",
    "   \\hat{\\theta}_n = \\frac{1}{n} \\sum_{i=1}^n e^{-U_i^2}\n",
    "   $$\n",
    "4. Aumentar $n$ para reducir el error.\n",
    "\n",
    "---\n",
    "\n",
    "## 6️⃣ Cálculo a mano (ejemplo con $n=5$)\n",
    "\n",
    "Supongamos que generamos los siguientes $U_i$ con una tabla de números aleatorios (uniformes en \\[0,1]):\n",
    "\n",
    "| $i$ | $U_i$ | $e^{-U_i^2}$                 |\n",
    "| --- | ----- | ---------------------------- |\n",
    "| 1   | 0.12  | $e^{-0.0144} \\approx 0.9857$ |\n",
    "| 2   | 0.57  | $e^{-0.3249} \\approx 0.7229$ |\n",
    "| 3   | 0.93  | $e^{-0.8649} \\approx 0.4212$ |\n",
    "| 4   | 0.34  | $e^{-0.1156} \\approx 0.8909$ |\n",
    "| 5   | 0.78  | $e^{-0.6084} \\approx 0.5442$ |\n",
    "\n",
    "Promedio:\n",
    "\n",
    "$$\n",
    "\\hat{\\theta}_5 \\approx \\frac{0.9857 + 0.7229 + 0.4212 + 0.8909 + 0.5442}{5} \\approx 0.713\n",
    "$$\n",
    "\n",
    "El valor real es $ \\theta \\approx 0.746824$, así que el error relativo con $n=5$ es $\\approx 4.5\\%$.\n",
    "\n",
    "---\n",
    "\n",
    "## 7️⃣ Convergencia y error\n",
    "\n",
    "En Monte Carlo, el error típico decrece como:\n",
    "\n",
    "$$\n",
    "\\text{Error} \\approx \\frac{\\sigma}{\\sqrt{n}}\n",
    "$$\n",
    "\n",
    "donde $\\sigma^2$ es la varianza de $g(U)$.\n",
    "\n",
    "Esto significa que para reducir el error en un factor de 10, necesitamos multiplicar $n$ por 100.\n",
    "\n",
    "---\n",
    "\n",
    "## 8️⃣ Interpretación final\n",
    "\n",
    "* **Concepto clave:** La integral definida es un valor esperado.\n",
    "* **LGN:** Nos asegura convergencia del promedio muestral al valor esperado.\n",
    "* **Monte Carlo:** Usa la LGN para aproximar integrales y otros problemas.\n",
    "* **Ventaja:** No depende de la dimensión; útil para integrales multidimensionales.\n",
    "* **Desventaja:** Convergencia lenta ($O(1/\\sqrt{n})$).\n",
    "\n",
    "---\n",
    "\n",
    "Si quieres, puedo ahora hacer **la demostración teórica de por qué $E[g(U)] = \\int_0^1 g(x) dx$** y luego mostrarte **el cálculo exacto de la varianza** para estimar el error de Monte Carlo en este ejemplo, que es algo que a menudo preguntan en exámenes.\n",
    "¿Quieres que lo haga?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e4d584",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib\n",
    "matplotlib.use(\"TkAgg\")  # o \"Qt5Agg\" si tienes PyQt5 instalado\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Slider, Button\n",
    "\n",
    "# ======= CONFIGURACIÓN =======\n",
    "theta_true = 0.5 * math.sqrt(math.pi) * math.erf(1.0)  # valor real\n",
    "N_MAX = 5000\n",
    "RUNS = 5\n",
    "rng = np.random.default_rng(20250812)\n",
    "\n",
    "def mc_run(n_max):\n",
    "    u = rng.random(n_max)\n",
    "    g = np.exp(-u**2)\n",
    "    cum_mean = np.cumsum(g) / np.arange(1, n_max + 1)\n",
    "    return cum_mean\n",
    "\n",
    "runs = [mc_run(N_MAX) for _ in range(RUNS)]\n",
    "run_idx = 0\n",
    "n_init = 100\n",
    "\n",
    "# ======= PLOTEO =======\n",
    "fig, ax = plt.subplots()\n",
    "plt.subplots_adjust(bottom=0.25)\n",
    "line_mc, = ax.plot(np.arange(1, n_init+1), runs[run_idx][:n_init], lw=2)\n",
    "ax.axhline(y=theta_true, color='r', linestyle='--', label=f\"Valor real = {theta_true:.6f}\")\n",
    "ax.set_xlabel(\"Número de muestras (n)\")\n",
    "ax.set_ylabel(\"Media muestral de g(U)\")\n",
    "ax.set_title(r\"Monte Carlo $\\int_0^1 e^{-x^2} dx$\")\n",
    "ax.legend()\n",
    "\n",
    "# Slider para n\n",
    "ax_slider = plt.axes([0.25, 0.1, 0.5, 0.03])\n",
    "slider_n = Slider(ax_slider, 'n', 10, N_MAX, valinit=n_init, valstep=10)\n",
    "\n",
    "def update(val):\n",
    "    n = int(slider_n.val)\n",
    "    line_mc.set_xdata(np.arange(1, n + 1))\n",
    "    line_mc.set_ydata(runs[run_idx][:n])\n",
    "    ax.relim()\n",
    "    ax.autoscale_view()\n",
    "    fig.canvas.draw_idle()\n",
    "\n",
    "slider_n.on_changed(update)\n",
    "\n",
    "# Botón para cambiar corrida\n",
    "ax_button = plt.axes([0.8, 0.025, 0.1, 0.04])\n",
    "btn = Button(ax_button, 'Run++')\n",
    "\n",
    "def resample(event):\n",
    "    global run_idx, runs\n",
    "    run_idx = (run_idx + 1) % RUNS\n",
    "    runs[run_idx] = mc_run(N_MAX)\n",
    "    update(slider_n.val)\n",
    "\n",
    "btn.on_clicked(resample)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c98bab",
   "metadata": {},
   "source": [
    "El **error** que pusimos en el gráfico, $\\sigma / \\sqrt{n}$, es una **estimación de la desviación estándar** del estimador de Monte Carlo $\\hat{\\theta}_n$.\n",
    "Su interpretación conecta directamente con la **distribución muestral** y los **intervalos de confianza**.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Contexto matemático\n",
    "\n",
    "Partimos de que:\n",
    "\n",
    "$$\n",
    "\\hat{\\theta}_n = \\frac{1}{n} \\sum_{i=1}^n g(U_i)\n",
    "$$\n",
    "\n",
    "con $U_i \\stackrel{iid}{\\sim} \\text{Uniform}(0,1)$.\n",
    "\n",
    "* **Media del estimador**:\n",
    "\n",
    "$$\n",
    "E[\\hat{\\theta}_n] = \\theta\n",
    "$$\n",
    "\n",
    "* **Varianza del estimador**:\n",
    "\n",
    "$$\n",
    "\\text{Var}(\\hat{\\theta}_n) = \\frac{\\sigma^2}{n}\n",
    "$$\n",
    "\n",
    "donde\n",
    "\n",
    "$$\n",
    "\\sigma^2 = \\text{Var}[g(U)]\n",
    "$$\n",
    "\n",
    "es la varianza de la función evaluada en una muestra uniforme.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. El papel de $\\sigma / \\sqrt{n}$\n",
    "\n",
    "* $\\sigma / \\sqrt{n}$ **mide la dispersión típica** de las estimaciones $\\hat{\\theta}_n$ alrededor del valor real $\\theta$.\n",
    "* Cuanto **más grande $n$**, más pequeño es este error, y por la **Ley de los Grandes Números** la estimación converge a $\\theta$.\n",
    "\n",
    "**Interpretación probabilística**:\n",
    "Si el **Teorema Central del Límite** aplica, entonces:\n",
    "\n",
    "$$\n",
    "\\hat{\\theta}_n \\approx \\mathcal{N}(\\theta, \\sigma^2/n)\n",
    "$$\n",
    "\n",
    "y podemos decir:\n",
    "\n",
    "$$\n",
    "P\\left( |\\hat{\\theta}_n - \\theta| \\leq z_{0.975} \\frac{\\sigma}{\\sqrt{n}} \\right) \\approx 0.95\n",
    "$$\n",
    "\n",
    "donde $z_{0.975} \\approx 1.96$.\n",
    "\n",
    "Esto significa que **en el 95% de las simulaciones**, el valor estimado cae dentro del intervalo:\n",
    "\n",
    "$$\n",
    "\\hat{\\theta}_n \\pm 1.96 \\cdot \\frac{\\sigma}{\\sqrt{n}}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Ejemplo numérico\n",
    "\n",
    "En nuestro caso:\n",
    "\n",
    "* Para $n=100$, el error típico puede ser del orden de $ \\approx 0.01$.\n",
    "* Para $n=10\\,000$, el error baja a $ \\approx 0.001$.\n",
    "\n",
    "Esto refleja la propiedad fundamental de Monte Carlo:\n",
    "\n",
    "$$\n",
    "\\text{Precisión} \\ \\propto \\frac{1}{\\sqrt{n}}\n",
    "$$\n",
    "\n",
    "doblar la precisión requiere **cuadruplicar** el número de simulaciones.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Resumen interpretativo\n",
    "\n",
    "* El **error** no es un “fallo” del método, sino una medida cuantitativa de la **incertidumbre estadística**.\n",
    "* Sirve para **construir intervalos de confianza** y decidir cuándo el estimador está “suficientemente cerca” del valor real para el nivel de precisión que necesitamos.\n",
    "* En Monte Carlo, **mejorar la precisión es caro**, porque el error decrece lentamente ($O(n^{-1/2})$).\n",
    "\n",
    "---\n",
    "\n",
    "Si quieres, puedo modificar el **código interactivo** para que, además de mostrar la estimación y el error, te dibuje **el intervalo de confianza del 95% en tiempo real** al mover el slider. Esto te daría una visualización clara de cómo el error encoge con $n$.\n",
    "¿Quieres que lo haga así?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a120b290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib\n",
    "matplotlib.use(\"TkAgg\")  # Backend interactivo compatible con sliders\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Slider, Button\n",
    "\n",
    "# ======= CONFIGURACIÓN =======\n",
    "theta_true = 0.5 * math.sqrt(math.pi) * math.erf(1.0)  # valor real\n",
    "N_MAX = 5000\n",
    "RUNS = 5\n",
    "rng = np.random.default_rng(20250812)\n",
    "\n",
    "def mc_run(n_max):\n",
    "    u = rng.random(n_max)\n",
    "    g = np.exp(-u**2)\n",
    "    cum_mean = np.cumsum(g) / np.arange(1, n_max + 1)\n",
    "    cum_var = np.cumsum((g - cum_mean)**2) / np.arange(1, n_max + 1)\n",
    "    sigma_hat = np.sqrt(cum_var)  # desviación estándar estimada\n",
    "    error = sigma_hat / np.sqrt(np.arange(1, n_max + 1))\n",
    "    return cum_mean, error\n",
    "\n",
    "runs = [mc_run(N_MAX) for _ in range(RUNS)]\n",
    "run_idx = 0\n",
    "n_init = 100\n",
    "\n",
    "# ======= PLOTEO =======\n",
    "fig, ax = plt.subplots()\n",
    "plt.subplots_adjust(bottom=0.25)\n",
    "line_mc, = ax.plot(np.arange(1, n_init+1), runs[run_idx][0][:n_init], lw=2, label=\"Estimación Monte Carlo\")\n",
    "line_upper, = ax.plot(np.arange(1, n_init+1), runs[run_idx][0][:n_init] + 1.96 * runs[run_idx][1][:n_init],\n",
    "                      'g--', lw=1, label=\"IC 95%\")\n",
    "line_lower, = ax.plot(np.arange(1, n_init+1), runs[run_idx][0][:n_init] - 1.96 * runs[run_idx][1][:n_init],\n",
    "                      'g--', lw=1)\n",
    "ax.axhline(y=theta_true, color='r', linestyle='--', label=f\"Valor real = {theta_true:.6f}\")\n",
    "ax.set_xlabel(\"Número de muestras (n)\")\n",
    "ax.set_ylabel(\"Estimación e intervalo\")\n",
    "ax.set_title(r\"Monte Carlo $\\int_0^1 e^{-x^2} dx$ con IC 95%\")\n",
    "ax.legend()\n",
    "\n",
    "# Slider para n\n",
    "ax_slider = plt.axes([0.25, 0.1, 0.5, 0.03])\n",
    "slider_n = Slider(ax_slider, 'n', 10, N_MAX, valinit=n_init, valstep=10)\n",
    "\n",
    "def update(val):\n",
    "    n = int(slider_n.val)\n",
    "    mean_vals, err_vals = runs[run_idx]\n",
    "    line_mc.set_xdata(np.arange(1, n + 1))\n",
    "    line_mc.set_ydata(mean_vals[:n])\n",
    "    line_upper.set_xdata(np.arange(1, n + 1))\n",
    "    line_upper.set_ydata(mean_vals[:n] + 1.96 * err_vals[:n])\n",
    "    line_lower.set_xdata(np.arange(1, n + 1))\n",
    "    line_lower.set_ydata(mean_vals[:n] - 1.96 * err_vals[:n])\n",
    "    ax.relim()\n",
    "    ax.autoscale_view()\n",
    "    fig.canvas.draw_idle()\n",
    "\n",
    "slider_n.on_changed(update)\n",
    "\n",
    "# Botón para cambiar corrida\n",
    "ax_button = plt.axes([0.8, 0.025, 0.1, 0.04])\n",
    "btn = Button(ax_button, 'Run++')\n",
    "\n",
    "def resample(event):\n",
    "    global run_idx, runs\n",
    "    run_idx = (run_idx + 1) % RUNS\n",
    "    runs[run_idx] = mc_run(N_MAX)\n",
    "    update(slider_n.val)\n",
    "\n",
    "btn.on_clicked(resample)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4fbc36",
   "metadata": {},
   "source": [
    "Formalmente, la interpretación de un **intervalo de confianza (IC)** no es que contenga el valor verdadero con cierta probabilidad —esa es una idea intuitiva pero técnicamente incorrecta desde el punto de vista frecuentista—, sino algo más sutil y ligado al concepto de repetición muestral y cobertura.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Definición formal frecuentista\n",
    "\n",
    "Sea $\\theta$ un parámetro fijo pero desconocido (por ejemplo, el valor real de una integral o la media de una población). Un intervalo de confianza al nivel $1-\\alpha$ es una regla que, aplicada a una muestra aleatoria, produce un intervalo aleatorio $[L(X), U(X)]$ tal que:\n",
    "\n",
    "$$\n",
    "P_\\theta\\big( L(X) \\leq \\theta \\leq U(X) \\big) = 1 - \\alpha\n",
    "$$\n",
    "\n",
    "donde:\n",
    "\n",
    "* $X$ es el vector de observaciones aleatorias,\n",
    "* $L(X)$ y $U(X)$ son funciones de los datos,\n",
    "* la probabilidad se entiende sobre el mecanismo aleatorio que genera $X$, **no sobre $\\theta$**.\n",
    "\n",
    "Esto significa: **si repitiéramos infinitamente el experimento de muestreo**, la proporción de intervalos que cubrirían el valor real $\\theta$ sería $1 - \\alpha$.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Interpretación correcta vs. incorrecta\n",
    "\n",
    "* ✅ **Correcta:**\n",
    "  “Si repitiéramos este procedimiento muchas veces bajo las mismas condiciones, el $95\\%$ de los intervalos obtenidos contendrían el verdadero valor del parámetro.”\n",
    "\n",
    "* ❌ **Incorrecta:**\n",
    "  “La probabilidad de que este intervalo en particular contenga $\\theta$ es $95\\%$.”\n",
    "  Esto sería una interpretación **bayesiana**, donde el parámetro es aleatorio y la probabilidad se refiere a la incertidumbre sobre él dada la evidencia.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. En el contexto de Monte Carlo y el error $\\sigma/\\sqrt{n}$\n",
    "\n",
    "En el estimador de Monte Carlo:\n",
    "\n",
    "$$\n",
    "\\hat{\\theta}_n = \\frac{1}{n} \\sum_{i=1}^n g(U_i)\n",
    "$$\n",
    "\n",
    "con $U_i \\sim \\text{Uniform}(0,1)$, se cumple que para $n$ grande:\n",
    "\n",
    "$$\n",
    "\\hat{\\theta}_n \\overset{\\text{aprox.}}{\\sim} \\mathcal{N}\\left( \\theta, \\frac{\\sigma^2}{n} \\right)\n",
    "$$\n",
    "\n",
    "por el **Teorema Central del Límite (TCL)**, donde $\\sigma^2 = \\mathrm{Var}[g(U)]$.\n",
    "\n",
    "Un intervalo de confianza al $95\\%$ sería:\n",
    "\n",
    "$$\n",
    "\\hat{\\theta}_n \\pm z_{0.975} \\cdot \\frac{\\sigma}{\\sqrt{n}}\n",
    "$$\n",
    "\n",
    "con $z_{0.975} \\approx 1.96$.\n",
    "\n",
    "Interpretación formal: **si repitiéramos muchas simulaciones Monte Carlo con el mismo $n$**, el 95% de los intervalos construidos así contendrían el valor verdadero $\\theta$.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Conexión con cobertura y convergencia\n",
    "\n",
    "* El ancho del intervalo **disminuye como** $\\mathcal{O}(n^{-1/2})$.\n",
    "* Un intervalo más estrecho **no garantiza** que cubra al valor real más veces; el nivel de confianza depende de la construcción estadística.\n",
    "* El papel de la **Ley de los Grandes Números** es asegurar que el centro del intervalo ($\\hat{\\theta}_n$) converge a $\\theta$; el papel del **TCL** es dar la distribución aproximada y así construir el intervalo.\n",
    "\n",
    "---\n",
    "\n",
    "Si quieres, puedo modificar el código que ya tienes para que además de graficar la estimación y el error $\\sigma/\\sqrt{n}$, dibuje **en tiempo real el intervalo de confianza al 95%** para que se vea visualmente cómo “atrapa” o no al valor real. Esto es útil para examen y para comprender cobertura.\n",
    "¿Quieres que lo haga?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "u",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
